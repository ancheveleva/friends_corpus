{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b70aa44",
   "metadata": {},
   "source": [
    "**1. Данные из таблички**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc7a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0eef17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_excel(\"./friends_full_data_checked.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5eb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_all.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9231c49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>monica_lines</th>\n",
       "      <th>joey_lines</th>\n",
       "      <th>chandler_lines</th>\n",
       "      <th>phoebe_lines</th>\n",
       "      <th>ross_lines</th>\n",
       "      <th>rachel_lines</th>\n",
       "      <th>scriptwriters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>Yeah, you really shouldn't.  By the way, how ...</td>\n",
       "      <td>Well anyway, I'm glad you're back, I really n...</td>\n",
       "      <td>So, where's Mike? Hey. Why are you wearing my...</td>\n",
       "      <td>Hi Oh, he's at the doctor, he didn't poop the...</td>\n",
       "      <td>Joey, you shouldn't lie on your résumé.  It w...</td>\n",
       "      <td>How was the honeymoon? Oh! I did not know you...</td>\n",
       "      <td>Sherry Bilsing-Graham, Ellen Plummer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>Well, because every time we do, you make joke...</td>\n",
       "      <td>Guess what?  I finally got that seed out of ...</td>\n",
       "      <td>Yeah, I don't know why we hang out with marri...</td>\n",
       "      <td>Oh! Yeah, this is fun, couples night. Wow! I ...</td>\n",
       "      <td>Hey, you guys... I have great news. Oh, well...</td>\n",
       "      <td>Hi you guys. Ooh, Italian!   Hey you guys......</td>\n",
       "      <td>Tracy Reilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Hey, this afternoon you said you'd be support...</td>\n",
       "      <td>Hey, great! All right! What? No, no, no! No, ...</td>\n",
       "      <td>How did the job stuff go? Or facing a bitch o...</td>\n",
       "      <td>Ooh, what's going on? Good for you! Of course...</td>\n",
       "      <td>You know what? This calls for a bottle of Is...</td>\n",
       "      <td>He offered me one. The job is in Paris.  Oh, ...</td>\n",
       "      <td>Marta Kauffman, David Crane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>Hey, Rach, you're leaving tomorrow, shouldn't...</td>\n",
       "      <td>All right, all right, all right, let's play o...</td>\n",
       "      <td>Hey! So we thought we'd throw you little goin...</td>\n",
       "      <td>Hey! Oh, he has a gig. I kinda like being mar...</td>\n",
       "      <td>Hey!  Hey Erica, welcome back to town!  Wow, ...</td>\n",
       "      <td>Ok! Can't believe I'm risking  this again, bu...</td>\n",
       "      <td>Andrew Reich, Ted Cohen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>Erica, are you okay? Oh my God! She doesn't h...</td>\n",
       "      <td>Hey! It's my house-warming present for Monica...</td>\n",
       "      <td>Relax! We'll just get her some antacids. Oh m...</td>\n",
       "      <td>Morning. What's that? It's a baby chick and d...</td>\n",
       "      <td>Rach! Hey. Oh. This was amazing. Yeah, well, ...</td>\n",
       "      <td>So if you think I didn't say goodbye to you b...</td>\n",
       "      <td>Marta Kauffman, David Crane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  episode                                       monica_lines  \\\n",
       "222      10       13   Yeah, you really shouldn't.  By the way, how ...   \n",
       "223      10       14   Well, because every time we do, you make joke...   \n",
       "224      10       15   Hey, this afternoon you said you'd be support...   \n",
       "225      10       16   Hey, Rach, you're leaving tomorrow, shouldn't...   \n",
       "226      10       17   Erica, are you okay? Oh my God! She doesn't h...   \n",
       "\n",
       "                                            joey_lines  \\\n",
       "222   Well anyway, I'm glad you're back, I really n...   \n",
       "223    Guess what?  I finally got that seed out of ...   \n",
       "224   Hey, great! All right! What? No, no, no! No, ...   \n",
       "225   All right, all right, all right, let's play o...   \n",
       "226   Hey! It's my house-warming present for Monica...   \n",
       "\n",
       "                                        chandler_lines  \\\n",
       "222   So, where's Mike? Hey. Why are you wearing my...   \n",
       "223   Yeah, I don't know why we hang out with marri...   \n",
       "224   How did the job stuff go? Or facing a bitch o...   \n",
       "225   Hey! So we thought we'd throw you little goin...   \n",
       "226   Relax! We'll just get her some antacids. Oh m...   \n",
       "\n",
       "                                          phoebe_lines  \\\n",
       "222   Hi Oh, he's at the doctor, he didn't poop the...   \n",
       "223   Oh! Yeah, this is fun, couples night. Wow! I ...   \n",
       "224   Ooh, what's going on? Good for you! Of course...   \n",
       "225   Hey! Oh, he has a gig. I kinda like being mar...   \n",
       "226   Morning. What's that? It's a baby chick and d...   \n",
       "\n",
       "                                            ross_lines  \\\n",
       "222   Joey, you shouldn't lie on your résumé.  It w...   \n",
       "223    Hey, you guys... I have great news. Oh, well...   \n",
       "224    You know what? This calls for a bottle of Is...   \n",
       "225   Hey!  Hey Erica, welcome back to town!  Wow, ...   \n",
       "226   Rach! Hey. Oh. This was amazing. Yeah, well, ...   \n",
       "\n",
       "                                          rachel_lines  \\\n",
       "222   How was the honeymoon? Oh! I did not know you...   \n",
       "223    Hi you guys. Ooh, Italian!   Hey you guys......   \n",
       "224   He offered me one. The job is in Paris.  Oh, ...   \n",
       "225   Ok! Can't believe I'm risking  this again, bu...   \n",
       "226   So if you think I didn't say goodbye to you b...   \n",
       "\n",
       "                            scriptwriters  \n",
       "222  Sherry Bilsing-Graham, Ellen Plummer  \n",
       "223                          Tracy Reilly  \n",
       "224           Marta Kauffman, David Crane  \n",
       "225               Andrew Reich, Ted Cohen  \n",
       "226           Marta Kauffman, David Crane  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580aa05c",
   "metadata": {},
   "source": [
    "**2. Модули и модели для парсинга**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a85a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.61.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af14347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff157b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e934401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# для разбиения на предложения (модель слишком умная)\n",
    "nlp_sent_segm = English()\n",
    "nlp_sent_segm.add_pipe(\"sentencizer\")\n",
    "\n",
    "# для постеггинга и лемматизации\n",
    "nlp_pos = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3afe35dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_pos(\"him\")[0].lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e4d31",
   "metadata": {},
   "source": [
    "**3. Разбиение на предложения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3c426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces = re.compile(r'\\s{2,}')\n",
    "def sent_segm(episode):\n",
    "    d = spaces.sub(' ', episode)\n",
    "    d = d.replace(\"’\", \"'\")\n",
    "    d = nlp_sent_segm(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea02c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = data_all.columns[2:8]\n",
    "for character in characters:\n",
    "    data_all[character] = data_all[character].apply(sent_segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fe3b4",
   "metadata": {},
   "source": [
    "**4. Работа с БД: создание и функция записи**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e00868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5305eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"./friends_corpus.db\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7099dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Match \n",
    "(pr_key integer PRIMARY KEY, sentence_id integer, token_id integer)\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Sentences\n",
    "(sentence_id integer PRIMARY KEY, sentence text, annotated text)\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Meta\n",
    "(sentence_id integer PRIMARY KEY, character text, episode integer, \n",
    "season integer, scriptwriters text)\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Tokens\n",
    "(token_id integer PRIMARY KEY, token text, lemma_id integer)\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Lemmas\n",
    "(lemma_id integer PRIMARY KEY, lemma text, pos text)\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de735ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_char_to_db(char_dict):\n",
    "    conn = sqlite3.connect(\"./friends_corpus.db\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"INSERT INTO Sentences VALUES (?, ?, ?)\", \n",
    "               (char_dict[\"sentence_id\"], char_dict[\"sentence\"], \n",
    "                char_dict[\"annotated\"]))\n",
    "    cur.execute(\"INSERT INTO Meta VALUES (?, ?, ?, ?, ?)\", \n",
    "               (char_dict[\"sentence_id\"], char_dict[\"character\"], \n",
    "                char_dict[\"episode\"], char_dict[\"season\"],\n",
    "                char_dict[\"scriptwriters\"]))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba2aad",
   "metadata": {},
   "source": [
    "**5. Морфпарсинг и запись в БД размеченных предложений и мета инфы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b9926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 227/227 [01:16<00:00,  2.96it/s]\n",
      "100%|█████████████████████████████████████████| 227/227 [01:21<00:00,  2.79it/s]\n",
      "100%|█████████████████████████████████████████| 227/227 [01:21<00:00,  2.80it/s]\n",
      "100%|█████████████████████████████████████████| 227/227 [01:21<00:00,  2.79it/s]\n",
      "100%|█████████████████████████████████████████| 227/227 [01:28<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████| 227/227 [01:27<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_id = 0\n",
    "\n",
    "for character in characters: # для каждого персонажа\n",
    "    i = 0\n",
    "    for row in tqdm(data_all[character]): # для каждой серии\n",
    "        season = data_all.loc[i, \"season\"]\n",
    "        episode = data_all.loc[i, \"episode\"]\n",
    "        scriptwriters = data_all.loc[i, \"scriptwriters\"]\n",
    "        i += 1\n",
    "        for sent in row.sents: # для каждого его/её предложения из этой серии\n",
    "            s = sent.text.strip()\n",
    "            if s: # если не пустая строка\n",
    "                data_parsed = {}\n",
    "                data_parsed[\"sentence\"] = s\n",
    "                s = nlp_pos(s) # тут другой спэйси, модельный\n",
    "                s_ann = []\n",
    "                for token in s:\n",
    "                    s_ann.append('+'.join([token.text.lower(), token.lemma_, token.pos_]))\n",
    "                data_parsed[\"annotated\"] = ' '.join(s_ann)\n",
    "\n",
    "                data_parsed[\"character\"] = character\n",
    "                data_parsed[\"season\"] = int(season)\n",
    "                data_parsed[\"episode\"] = int(episode)\n",
    "                data_parsed[\"scriptwriters\"] = scriptwriters\n",
    "                data_parsed[\"sentence_id\"] = int(sent_id)\n",
    "                sent_id += 1\n",
    "\n",
    "                write_char_to_db(data_parsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c66c73",
   "metadata": {},
   "source": [
    "**6. Таблицы лемм и токенов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a5b11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"./friends_corpus.db\")\n",
    "df_annot = pd.read_sql_query(\"SELECT sentence_id, annotated FROM Sentences\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d26d034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>annotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>there+there+PRON 's+be+AUX nothing+nothing+PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>he+he+PRON 's+be+AUX just+just+ADV some+some+D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>okay+okay+INTJ ,+,+PUNCT everybody+everybody+P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this+this+DET is+be+AUX not+not+PART even+even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it+it+PRON 's+be+AUX just+just+ADV two+two+NUM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                          annotated\n",
       "0            0  there+there+PRON 's+be+AUX nothing+nothing+PRO...\n",
       "1            1  he+he+PRON 's+be+AUX just+just+ADV some+some+D...\n",
       "2            2  okay+okay+INTJ ,+,+PUNCT everybody+everybody+P...\n",
       "3            3  this+this+DET is+be+AUX not+not+PART even+even...\n",
       "4            4  it+it+PRON 's+be+AUX just+just+ADV two+two+NUM..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdac1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_lem_pos_str = \" \".join(df_annot[\"annotated\"])\n",
    "tok_lem_pos_set = set(tok_lem_pos_str.split(' '))\n",
    "\n",
    "tok_lem_pos = []\n",
    "lem_pos = []\n",
    "for tok_i, tlp in enumerate(tok_lem_pos_set):\n",
    "    tok, lem, pos = tlp.split(\"+\")\n",
    "    lempos = \"+\".join([lem, pos])\n",
    "    tok_lem_pos.append((tok_i, tok, lempos, tlp))\n",
    "    lem_pos.append((lempos, lem, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb692eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>l+p</th>\n",
       "      <th>t+l+p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>perked</td>\n",
       "      <td>perk+VERB</td>\n",
       "      <td>perked+perk+VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ons</td>\n",
       "      <td>ons+NOUN</td>\n",
       "      <td>ons+ons+NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dishes</td>\n",
       "      <td>dish+NOUN</td>\n",
       "      <td>dishes+dish+NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>effervesce</td>\n",
       "      <td>effervesce+VERB</td>\n",
       "      <td>effervesce+effervesce+VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>igneous</td>\n",
       "      <td>igneous+ADJ</td>\n",
       "      <td>igneous+igneous+ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_id       token              l+p                       t+l+p\n",
       "0         0      perked        perk+VERB            perked+perk+VERB\n",
       "1         1         ons         ons+NOUN                ons+ons+NOUN\n",
       "2         2      dishes        dish+NOUN            dishes+dish+NOUN\n",
       "3         3  effervesce  effervesce+VERB  effervesce+effervesce+VERB\n",
       "4         4     igneous      igneous+ADJ         igneous+igneous+ADJ"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = pd.DataFrame(tok_lem_pos,\n",
    "                         columns=[\"token_id\", \"token\", \"l+p\", \"t+l+p\"])\n",
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7dcdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17626, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmas = pd.DataFrame(lem_pos,\n",
    "                         columns=[\"l+p\", \"lemma\", \"pos\"])\n",
    "df_lemmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef520374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14968, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmas = df_lemmas.drop_duplicates(ignore_index=True)\n",
    "df_lemmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24992c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l+p</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perk+VERB</td>\n",
       "      <td>perk</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ons+NOUN</td>\n",
       "      <td>ons</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dish+NOUN</td>\n",
       "      <td>dish</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effervesce+VERB</td>\n",
       "      <td>effervesce</td>\n",
       "      <td>VERB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>igneous+ADJ</td>\n",
       "      <td>igneous</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               l+p       lemma   pos  lemma_id\n",
       "0        perk+VERB        perk  VERB         0\n",
       "1         ons+NOUN         ons  NOUN         1\n",
       "2        dish+NOUN        dish  NOUN         2\n",
       "3  effervesce+VERB  effervesce  VERB         3\n",
       "4      igneous+ADJ     igneous   ADJ         4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmas[\"lemma_id\"] = df_lemmas.index\n",
    "df_lemmas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccda6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokens_to_db = df_tokens.merge(df_lemmas, on=\"l+p\").drop([\"l+p\", \"t+l+p\", \"lemma\", \"pos\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5f2b5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>perked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dishes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6584</td>\n",
       "      <td>dish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>effervesce</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_id       token  lemma_id\n",
       "0         0      perked         0\n",
       "1         1         ons         1\n",
       "2         2      dishes         2\n",
       "3      6584        dish         2\n",
       "4         3  effervesce         3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens_to_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d73c36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perk</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ons</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dish</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effervesce</td>\n",
       "      <td>VERB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>igneous</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma   pos  lemma_id\n",
       "0        perk  VERB         0\n",
       "1         ons  NOUN         1\n",
       "2        dish  NOUN         2\n",
       "3  effervesce  VERB         3\n",
       "4     igneous   ADJ         4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmas_to_db = df_lemmas.drop(\"l+p\", axis=1)\n",
    "df_lemmas_to_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f221d7c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"./friends_corpus.db\")\n",
    "\n",
    "df_tokens_to_db.to_sql(\"Tokens\", con=conn, if_exists='append', index=False)\n",
    "df_lemmas_to_db.to_sql(\"Lemmas\", con=conn, if_exists='append', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3b65b",
   "metadata": {},
   "source": [
    "**7. Таблица мэтч**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e8640e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>annotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>there+there+PRON 's+be+AUX nothing+nothing+PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>he+he+PRON 's+be+AUX just+just+ADV some+some+D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>okay+okay+INTJ ,+,+PUNCT everybody+everybody+P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this+this+DET is+be+AUX not+not+PART even+even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it+it+PRON 's+be+AUX just+just+ADV two+two+NUM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                          annotated\n",
       "0            0  there+there+PRON 's+be+AUX nothing+nothing+PRO...\n",
       "1            1  he+he+PRON 's+be+AUX just+just+ADV some+some+D...\n",
       "2            2  okay+okay+INTJ ,+,+PUNCT everybody+everybody+P...\n",
       "3            3  this+this+DET is+be+AUX not+not+PART even+even...\n",
       "4            4  it+it+PRON 's+be+AUX just+just+ADV two+two+NUM..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "605835d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>t+l+p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>there+there+PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>'s+be+AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>nothing+nothing+PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>to+to+PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tell+tell+VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                 t+l+p\n",
       "0            0      there+there+PRON\n",
       "1            0             's+be+AUX\n",
       "2            0  nothing+nothing+PRON\n",
       "3            0            to+to+PART\n",
       "4            0        tell+tell+VERB"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = []\n",
    "for sent_id, annot in enumerate(list(df_annot[\"annotated\"])):\n",
    "    for tlp in annot.split(' '):\n",
    "        match.append((sent_id, tlp))\n",
    "\n",
    "df_match = pd.DataFrame(match, columns=[\"sentence_id\", \"t+l+p\"])\n",
    "df_match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c4663f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213</td>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214</td>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id\n",
       "0            0      6177\n",
       "1           45      6177\n",
       "2           46      6177\n",
       "3          213      6177\n",
       "4          214      6177"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match_to_db = df_match.merge(df_tokens, on=\"t+l+p\").drop([\"t+l+p\", \"token\", \"l+p\"], axis=1)\n",
    "df_match_to_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "890565e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_to_db = df_match_to_db.reset_index().rename(columns={\"index\": \"pr_key\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1c7463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"./friends_corpus.db\")\n",
    "\n",
    "df_match_to_db.to_sql(\"Match\", con=conn, if_exists='append', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5817f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
