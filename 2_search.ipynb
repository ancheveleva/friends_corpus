{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"2_search.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62jXXQaiW4li"
      },
      "source": [
        "# FRIENDS CORPUS\n",
        "\n",
        "Привет! Это протоверсия корпуса по сериалу «Друзья». \n",
        "\n",
        "Перед началом работы рекомендуем ознакомиться с [правилами работы корпуса](https://github.com/ancheveleva/friends_corpus/blob/main/README.md).\n",
        "\n",
        "Чтобы воспользоваться поиском, нажми **Run all**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSkQmUGz-TMC"
      },
      "source": [
        "## Реализация логики поиска"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l31imr98H_u"
      },
      "source": [
        "### Подгрузка базы данных, открытие соединения, инициализация языковой модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-cnZ4apgP3H"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "con = sqlite3.connect('friends_corpus_new.db')\n",
        "cursor = con.cursor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2Qt8-6h9Wqc"
      },
      "source": [
        "import spacy\n",
        "model = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvalh3-P8ST2"
      },
      "source": [
        "### Самые низкоуровневые функции: запросы идентификаторов параметров запроса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Saq9n0xPhwXa"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "def get_lemma_ids(lemma: str) -> List:\n",
        "    '''\n",
        "    retrives list of id corresponding to lemma\n",
        "    :param lemma: lema id of which is sought\n",
        "    :return: list of id corresponding to requested lemma\n",
        "    '''\n",
        "    cursor.execute('''SELECT lemma_id FROM Lemmas\n",
        "    WHERE lemma = ?''', (lemma,))\n",
        "    return [i[0] for i in cursor.fetchall()]\n",
        "\n",
        "\n",
        "def get_token_ids(lemma_ids: list) -> List:\n",
        "    '''\n",
        "    retrives list of tokens ids corresponding to lemma ids provided\n",
        "    :param lemma_ids: list of lemmas ids tokens of which are sought\n",
        "    :return: list of tokens ids corresponding to requested lemmas\n",
        "    '''\n",
        "    get_tokens_query = '''\n",
        "    SELECT token_id FROM Tokens\n",
        "    WHERE lemma_id = ?\n",
        "    '''\n",
        "    token_ids = []\n",
        "    for lemma_id in lemma_ids:\n",
        "        cursor.execute(get_tokens_query, (lemma_id,))\n",
        "        token_ids.extend([i[0] for i in cursor.fetchall()])\n",
        "    return token_ids\n",
        "\n",
        "\n",
        "def get_token_id(token: str) -> List:\n",
        "    '''\n",
        "    retrives list of id corresponding to token provided\n",
        "    :param token: token, id of which is sought\n",
        "    :return: list of id corresponding to requested token\n",
        "    '''\n",
        "    get_token_query = '''\n",
        "    SELECT token_id FROM Tokens\n",
        "    WHERE token = ?\n",
        "    '''\n",
        "    cursor.execute(get_token_query, (token,))\n",
        "    return [i[0] for i in cursor.fetchall()]\n",
        "\n",
        "\n",
        "def get_pos_lemma_ids(lemma: str, pos: str) -> List:\n",
        "    '''\n",
        "    retrives list of ids corresponding to lemma and pos\n",
        "    :param lemma: lema, id of which is sought\n",
        "    :param pos: condition on part-of-speech tag\n",
        "    :return: list of id corresponding to requested lemma + pos\n",
        "    '''\n",
        "    get_pos_lemma_query = '''\n",
        "    SELECT lemma_id FROM Lemmas\n",
        "    WHERE (lemma = ?) AND (pos = ?)\n",
        "    '''\n",
        "    cursor.execute(get_pos_lemma_query, (lemma, pos,))\n",
        "    try:\n",
        "        return cursor.fetchall()[0]\n",
        "    except IndexError:\n",
        "        return []\n",
        "\n",
        "\n",
        "def get_sentence_ids(token_ids: List) -> List:\n",
        "    '''\n",
        "    retrives list of sentences ids corresponding to token ids list\n",
        "    :param token_ids: list of token ids to be present in a sentence\n",
        "    :return: list of sentences ids containing at least one of requested tokens\n",
        "    '''\n",
        "    get_sent_query = '''\n",
        "    SELECT sentence_id FROM Match\n",
        "    WHERE token_id = ?\n",
        "    '''\n",
        "    sentence_ids = []\n",
        "    for token_id in token_ids:\n",
        "        cursor.execute(get_sent_query, (token_id,))\n",
        "        sentence_ids.extend([i[0] for i in cursor.fetchall()])\n",
        "    return sentence_ids\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dB5QMwg88J9"
      },
      "source": [
        "### Чуть более высокоуровневый функционал: поиск идентификаторов подходящих предложений по определенному параметру запроса, использующий функции предыдущего раздела"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZrJqFqE8jKp"
      },
      "source": [
        "def token_to_tokens(token: str, model=model) -> List:\n",
        "    '''\n",
        "    retrives list of sentences ids containing token in any form \n",
        "    :param token: token to be present in a sentence\n",
        "    :param model: language model to lemmatize token\n",
        "    :return: list of sentences ids containing any form of token provided\n",
        "    '''\n",
        "    lemma = model(token)[0].lemma_\n",
        "    if lemma.startswith('-') and lemma.endswith('-'):\n",
        "        lemma = token\n",
        "    return get_sentence_ids(get_token_ids(get_lemma_ids(lemma)))\n",
        "\n",
        "\n",
        "def token_to_token(token: str) -> List:\n",
        "    '''\n",
        "    retrives list of sentences ids containing token in the exact form provided\n",
        "    :param token: token to be present in a sentence\n",
        "    :return: list of sentences ids containing exact form of token provided\n",
        "    '''\n",
        "    return get_sentence_ids(get_token_id(token))\n",
        "\n",
        "\n",
        "def lemma_pos_to_token(token, pos):\n",
        "    '''\n",
        "    retrives list of sentences ids containing tokens with provided lemma\n",
        "    and specified pos tag\n",
        "    :param token: token to be present in a sentence\n",
        "    :pos: requested part-of-speech tag\n",
        "    :return: list of sentences ids containing specific tokens of exact pos\n",
        "    '''\n",
        "    return get_sentence_ids(get_token_ids(get_pos_lemma_ids(token, pos)))\n",
        "\n",
        "\n",
        "def pos_to_tokens(pos: str) -> List:\n",
        "    '''\n",
        "    retrives list of sentences ids containing tokens of requested part of speech\n",
        "    :param pos:requested part-of-speech tag\n",
        "    :return: list of sentences ids containing words of specified pos\n",
        "    '''\n",
        "    query = '''\n",
        "    SELECT sentence_id FROM Match\n",
        "    JOIN Tokens ON Match.token_id = Tokens.token_id\n",
        "    JOIN Lemmas ON Tokens.lemma_id = Lemmas.lemma_id\n",
        "    WHERE Lemmas.pos = ?\n",
        "    '''\n",
        "    cursor.execute(query, (pos,))\n",
        "    return [i[0] for i in cursor.fetchall()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4XKcg49UR-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEJqRMW9uxC"
      },
      "source": [
        "### Еще более высокоуровневая конструкция: функция, обрабатывающая цельный запрос, работающая на функциях, заданных выше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccrj8clRMwt_"
      },
      "source": [
        "import re\n",
        "from typing import Tuple\n",
        "\n",
        "tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
        "\n",
        "def execute_query(initial_query: str) -> Tuple[List, List]:\n",
        "    '''\n",
        "    interprets query, retrieves ids of candidates sentences,\n",
        "    provides regular expressions for filterng\n",
        "    :param initial_query: query to interpret and execute\n",
        "    :return: list of corresponding sentences id, list of patterns to look for\n",
        "    '''\n",
        "    queries = initial_query.split()\n",
        "    sentence_ids = {}\n",
        "    patterns = []\n",
        "\n",
        "    for query in queries:\n",
        "        if '+' in query:\n",
        "            lemma, pos = query.split('+')\n",
        "            new = set(lemma_pos_to_token(lemma, pos))\n",
        "            patterns.append(re.compile(f\"[a-zA-Z'\\-_]+\\+{lemma}\\+{pos}\"))\n",
        "        elif query in tags:\n",
        "            new = set(pos_to_tokens(query))\n",
        "            patterns.append(re.compile(f\"[a-zA-Z'\\-_]+\\+[a-zA-Z'\\-_]+\\+{query}\"))\n",
        "        elif query.startswith('\"') or query.startswith(\"'\"):\n",
        "            new = set(token_to_token(query[1:-1]))\n",
        "            patterns.append(re.compile(f\"{query[1:-1]}\\+[a-zA-Z'\\-_]+\\+[A-Z]+\"))\n",
        "        else:\n",
        "            new = set(token_to_tokens(query))\n",
        "            patterns.append(re.compile(f\"[a-zA-Z'\\-_]+\\+{query}\\+[A-Z]+\"))\n",
        "        # print(bool(new))\n",
        "        sentence_ids = sentence_ids.intersection(new) if sentence_ids else new\n",
        "    return sentence_ids, patterns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu8RA-PL-Atq"
      },
      "source": [
        "### Вспомогательные функции для валидации предложений по критерию порядка и расстояния"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TARrl5PAsLXH"
      },
      "source": [
        "def get_annotated(sents_id):    \n",
        "    get_annotated_query = f'''\n",
        "    SELECT sentence_id, annotated FROM Sentences\n",
        "    WHERE sentence_id IN ({('?, ' * len(sents_id))[:-2]})\n",
        "    '''\n",
        "    cursor.execute(get_annotated_query, tuple(sents_id))\n",
        "    return [i for i in cursor.fetchall()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDLypm3tvTbT"
      },
      "source": [
        "def is_valid(observed, last, sentence):\n",
        "    if not last:\n",
        "        last = observed.span()[-1]\n",
        "        return True, last\n",
        "    beg, end = observed.span()\n",
        "    return beg == last + 1, end\n",
        "\n",
        "def is_sentence_valid(sentence, patterns):\n",
        "\n",
        "    matched = []\n",
        "    for pattern in patterns:\n",
        "        matched.append([x for x in re.finditer(pattern, sentence)])\n",
        "\n",
        "    last = 0\n",
        "    correct = True\n",
        "\n",
        "    for match in matched:\n",
        "        if len(match) == 1:\n",
        "            observed = match[0]\n",
        "            valid, last = is_valid(observed, last, sentence)\n",
        "            if not valid:\n",
        "                correct = False\n",
        "                break\n",
        "        else:\n",
        "            valid_is_found = False\n",
        "            for observed in match:\n",
        "                if not valid_is_found:\n",
        "                    result = is_valid(observed, last, sentence)\n",
        "                    if result[0] == True:\n",
        "                        last = result[-1]\n",
        "                        valid_is_found = True\n",
        "            if not valid_is_found:\n",
        "                correct = False\n",
        "                break\n",
        "    return correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl_pXgt9-KLt"
      },
      "source": [
        "## Самая главная функция, соединющаяя все заданное выше в одну логику"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYQsGV0jVrlD"
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScXgW4LV5uGZ"
      },
      "source": [
        "def find(query: str) -> None:\n",
        "    '''\n",
        "    interprets and executes query, \n",
        "    filters corresponding sentences,\n",
        "    retrieves meta info, \n",
        "    creates csv file with output\n",
        "    :param query: query to execute\n",
        "    '''\n",
        "    sentences_ids, patterns = execute_query(query)\n",
        "    annotated = get_annotated(sentences_ids)\n",
        "    valid = [sentence[0] for sentence in annotated if is_sentence_valid(sentence[-1], patterns)]\n",
        "\n",
        "    get_everything = f'''\n",
        "    SELECT sentence, character, episode, season, scriptwriters\n",
        "    FROM Sentences\n",
        "    JOIN Meta ON Sentences.sentence_id = Meta.sentence_id\n",
        "    WHERE Sentences.sentence_id IN ({('?, ' * len(valid))[:-2]})\n",
        "    '''\n",
        "\n",
        "    cursor.execute(get_everything, valid)\n",
        "\n",
        "    result = cursor.fetchall()\n",
        "    num_res = len(result)\n",
        "    if num_res == 0:\n",
        "        print(\"\"\"К сожалению, по данному запросу ничего не найдено :(\n",
        "Проверь, соответствует ли запрос правилам.\"\"\")\n",
        "    else:\n",
        "        with open(\"./results.csv\", 'w', newline='') as myfile:\n",
        "            wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "            wr.writerow([\"sentence\", \"character\", \"episode\", \"season\", \"scriptwriters\"])\n",
        "            for sent in result:\n",
        "                wr.writerow(sent)\n",
        "        print(f\"\"\"Количество предложений, содержащих данный запрос: {num_res}\n",
        "Они записаны в файл results.csv ;)\n",
        "Не забудь переименовать этот файл перед следующим запросом!\"\"\")\n",
        "    #return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UxTOGYx-ZU5"
      },
      "source": [
        "## Интерфейс поиска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elutrix8FViM",
        "outputId": "a1e59fa6-d73f-4c33-d5f3-ab605560e0a3"
      },
      "source": [
        "print(\"Введи запрос (напоминаем о правилах запроса вот здесь https://github.com/ancheveleva/friends_corpus/blob/main/README.md ):\")\n",
        "find(input())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введи запрос (напоминаем о правилах запроса вот здесь https://github.com/ancheveleva/friends_corpus/blob/main/README.md ):\n",
            "do+AUX do+VERB\n",
            "Количество предложений, содержащих данный запрос: 4\n",
            "Они записаны в файл results.csv ;)\n",
            "Не забудь переименовать этот файл перед следующим запросом!\n"
          ]
        }
      ]
    }
  ]
}